{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcrawling\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01maw_crawl\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[1;32md:\\Repos\\Universidad\\discursos-enfermedades\\1. Adquisición de datos\\crawling.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver                              \u001b[38;5;66;03m# Scraping\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfirefox\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Options      \u001b[38;5;66;03m# Scraping\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup \u001b[38;5;28;01mas\u001b[39;00m bs                         \u001b[38;5;66;03m# Scraping\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m                                             \u001b[38;5;66;03m# Scraping\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m                                                   \u001b[38;5;66;03m# Manejo de archivos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import crawling as aw_crawl\n",
    "import glob\n",
    "import os\n",
    "from itertools import product\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noticias epidemiológicas\n",
    "\n",
    "Aproximadamente, el código demora 2h 28 minutos en recolectar las noticias de un chunk de cuatro enfermedades desde enero del 2005 hasta diciembre de 2024.\n",
    "* No hay mayores problemas con colocar fechas imposibles, salvo un mayor tiempo de procesamiento. El query en Google solo indicará que no se encontraron resultados y, dado nuestro algoritmo, ignorará estos enlaces.\n",
    "\n",
    "Si bien se ejecutó en paralelo, el tiempo total de procesamiento equivale a 17h 16 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datecombo = list(product(range(2005,2025),range(1,13)))\n",
    "with open('diseases.txt','r') as f:\n",
    "    diseases = [dis[:-1] for dis in f.readlines()]\n",
    "    \n",
    "subset = diseases[:5]\n",
    "\n",
    "for disease in subset:\n",
    "    print(f'{disease}: {dt.now()}')\n",
    "    \n",
    "    for datetuple in datecombo:\n",
    "        aw_crawl.google_crawl(disease,aw_crawl.resolve_date(datetuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDC MINSA\n",
    "\n",
    "Inicialmente, tardó 10 horas (584 minutos y 46 segundos) en extraer todos los pdfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "años = list(range(2005,2025))\n",
    "with Pool(processes=6) as pool:\n",
    "    pool.map(aw_crawl.cdc_pdfs,años)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de PDFs recolectados: 3840\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_pdfs = [file for file in glob.glob('pdfs/**/*',recursive=True) if not os.path.isdir(file)]\n",
    "print(f'Cantidad de PDFs recolectados: {len(all_pdfs)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
